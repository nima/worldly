{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voice\n",
    "\n",
    "I'm shelving this until OpenAI exposes their melodic poet voice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os.environ[\"VIRTUAL_ENV\"]='/Users/nima/.local/share/virtualenvs/worldly-6Xoo3lh0'\n",
      "os.environ[\"PYTHONSTARTUP\"]='.repl.py'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "from jsonschema import validate\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n",
    "\n",
    "import os, dotenv, sys\n",
    "from pathlib import Path\n",
    "\n",
    "dotenv.load_dotenv(\"../.env\", override=True)\n",
    "print(f\"{os.environ[\"VIRTUAL_ENV\"]=}\")\n",
    "print(f\"{os.environ[\"PYTHONSTARTUP\"]=}\")\n",
    "parent = Path().resolve().parents[0].as_posix()\n",
    "if parent not in sys.path:\n",
    "    sys.path.insert(0, parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nima/.local/share/virtualenvs/worldly-6Xoo3lh0/lib/python3.12/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "import openai, whisper\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from openai import ChatCompletion\n",
    "\n",
    "import speech_recognition as sr\n",
    "import sqlite3\n",
    "from langdetect import detect\n",
    "from playsound import playsound\n",
    "from gtts import gTTS\n",
    "from playsound import playsound\n",
    "\n",
    "# Load Whisper model (choose \"base\" for faster or \"small\" for better accuracy)\n",
    "model = whisper.load_model(\"base\")\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x31a7196c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Database Setup\n",
    "conn = sqlite3.connect(\"words.db\")\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\n",
    "    \"\"\"CREATE TABLE IF NOT EXISTS words (word TEXT, language TEXT, correct_count INTEGER, wrong_count INTEGER)\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: Latin\n"
     ]
    }
   ],
   "source": [
    "def detect_language(text):\n",
    "    prompt = f\"\"\"You are a language expert who only detects languages from the following list: Sanskrit, Persian, and Latin. \n",
    "                 If the text matches one of these, respond with the language name (e.g., \"Latin\"). \n",
    "                 Otherwise, respond with \"None\". \n",
    "                 Here is the text: \"{text}\".\"\"\"\n",
    "    response = client.chat.completions.create(model=\"gpt-4\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "text = \"Salve, quid agis?\"\n",
    "detected_lang = detect_language(text)\n",
    "print(f\"Detected language: {detected_lang}\")\n",
    "\n",
    "\"\"\"_summary_\n",
    "async def detect_language(text):\n",
    "    prompt = f\"\"You are a language expert who detects whether text is in Sanskrit, Persian, or Latin. \n",
    "    If the text matches one of these, respond with the language name (e.g., \"Latin\"). \n",
    "    If it doesn't match, respond with \"None\". \n",
    "    Here is the text: \"{text}\".\"\"\n",
    "    \n",
    "    response = await openai.ChatCompletion.acreate(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a language detection assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return response['choices'][0]['message']['content'].strip()\n",
    "\n",
    "# Example usage\n",
    "async def main():\n",
    "    text = \"Salve, quid agis?\"\n",
    "    detected_lang = await detect_language(text)\n",
    "    print(f\"Detected language: {detected_lang}\")\n",
    "\n",
    "asyncio.run(main())\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persian Verse: \"برخاست و زین برگه زد برنگ زری\n",
      "بفرمود تا بیاورندش خری\"\n",
      "-Shahnameh, Ferdowsi\n"
     ]
    }
   ],
   "source": [
    "def generate_persian_text(prompt):\n",
    "    response: ChatCompletion = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert in Persian poetry and literature.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "persian_text = generate_persian_text(\"Provide a famous verse from the Shahnameh, in Persian.\")\n",
    "print(f\"Persian Verse: {persian_text.choices[0].message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Persian Text: \"به یاد کسی مرد نیکوکار نیست. هر آنکس که او با مردم ناخوش گذر کند.\"\n",
      "Audio saved to persian_poetry.mp3\n",
      "Audio saved to persian_poetry.mp3\n",
      "Audio saved to persian_poetry.mp3\n",
      "Audio saved to persian_poetry.mp3\n",
      "Audio saved to persian_poetry.mp3\n",
      "Audio saved to persian_poetry.mp3\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import requests\n",
    "import os\n",
    "from playsound import playsound\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "# Function to generate text using OpenAI\n",
    "def generate_text(prompt, language=\"Persian\"):\n",
    "    response: ChatCompletion = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": f\"You are a literature expert in {language}.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "# Function to generate audio using OpenAI TTS\n",
    "def text_to_speech_openai(text, filename=\"output.mp3\", voice=\"alloy\"):\n",
    "    url = \"https://api.openai.com/v1/audio/speech\"\n",
    "    headers = {\"Authorization\": f\"Bearer {openai.api_key}\", \"Content-Type\": \"application/json\"}\n",
    "    data = {\"model\": \"tts-1\", \"input\": text, \"voice\": voice}\n",
    "\n",
    "    # Generate audio\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        with open(filename, \"wb\") as audio_file:\n",
    "            audio_file.write(response.content)\n",
    "        print(f\"Audio saved to {filename}\")\n",
    "        playsound(filename)\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "\n",
    "\n",
    "# Main function to generate and play Persian poetry\n",
    "def main():\n",
    "    # Step 1: Generate Persian text\n",
    "    prompt = \"\"\"Provide a famous verse from the Shahnameh in Persia, in its original Persian.\n",
    "    Remember, I am speaking to you in Persian, and you are a Persian, without any non-Persian accent.\n",
    "    Also, please make to use the zebar, zir and piš, and so on, so that the text-to-speech will\n",
    "    not lack this data.  Your response should be very lean, only with the quoted verse from the\n",
    "    poem of your choice.\n",
    "    \"\"\"\n",
    "    persian_text = generate_text(prompt, language=\"Persian\")\n",
    "    print(f\"Generated Persian Text: {persian_text}\")\n",
    "\n",
    "    # Step 2: Convert to speech and play\n",
    "    for voice in [\"fable\", \"onyx\", \"nova\"]:\n",
    "        text_to_speech_openai(persian_text, filename=\"persian_poetry.mp3\", voice=voice)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You’re absolutely right — when interacting with OpenAI’s text-to-speech tools or other systems, the richness, emotion, and flow of poetry are key to creating an engaging experience. The voice you get from OpenAI’s current text-to-speech API (tts-1) is high quality but not tailored for expressive readings like poetry.\n",
    "\n",
    "In ChatGPT’s spoken responses (like on mobile), OpenAI likely uses a different pipeline or a more advanced model to add expressive intonation. Unfortunately, the public TTS models don’t yet include this richer style.\n",
    "\n",
    "Since OpenAI already demonstrates expressive intonation in its ChatGPT voice features (like the app version), it’s likely that an expressive TTS model will become available through their API in the future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
